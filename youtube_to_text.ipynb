{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /Users/danielfugisawa/Documents/playground/.conda/lib/python3.12/site-packages (1.12.0)\n",
      "Requirement already satisfied: yt-dlp in /Users/danielfugisawa/Documents/playground/.conda/lib/python3.12/site-packages (2023.12.30)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/danielfugisawa/Documents/playground/.conda/lib/python3.12/site-packages (from openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/danielfugisawa/Documents/playground/.conda/lib/python3.12/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/danielfugisawa/Documents/playground/.conda/lib/python3.12/site-packages (from openai) (0.26.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/danielfugisawa/Documents/playground/.conda/lib/python3.12/site-packages (from openai) (2.6.1)\n",
      "Requirement already satisfied: sniffio in /Users/danielfugisawa/Documents/playground/.conda/lib/python3.12/site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /Users/danielfugisawa/Documents/playground/.conda/lib/python3.12/site-packages (from openai) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /Users/danielfugisawa/Documents/playground/.conda/lib/python3.12/site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: mutagen in /Users/danielfugisawa/Documents/playground/.conda/lib/python3.12/site-packages (from yt-dlp) (1.47.0)\n",
      "Requirement already satisfied: pycryptodomex in /Users/danielfugisawa/Documents/playground/.conda/lib/python3.12/site-packages (from yt-dlp) (3.20.0)\n",
      "Requirement already satisfied: certifi in /Users/danielfugisawa/Documents/playground/.conda/lib/python3.12/site-packages (from yt-dlp) (2024.2.2)\n",
      "Requirement already satisfied: requests<3,>=2.31.0 in /Users/danielfugisawa/Documents/playground/.conda/lib/python3.12/site-packages (from yt-dlp) (2.31.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.26.17 in /Users/danielfugisawa/Documents/playground/.conda/lib/python3.12/site-packages (from yt-dlp) (2.2.0)\n",
      "Requirement already satisfied: websockets>=12.0 in /Users/danielfugisawa/Documents/playground/.conda/lib/python3.12/site-packages (from yt-dlp) (12.0)\n",
      "Requirement already satisfied: brotli in /Users/danielfugisawa/Documents/playground/.conda/lib/python3.12/site-packages (from yt-dlp) (1.1.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/danielfugisawa/Documents/playground/.conda/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/danielfugisawa/Documents/playground/.conda/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/danielfugisawa/Documents/playground/.conda/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/danielfugisawa/Documents/playground/.conda/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.2 in /Users/danielfugisawa/Documents/playground/.conda/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (2.16.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/danielfugisawa/Documents/playground/.conda/lib/python3.12/site-packages (from requests<3,>=2.31.0->yt-dlp) (3.3.2)\n",
      "Collecting git+https://github.com/openai/whisper.git\n",
      "  Cloning https://github.com/openai/whisper.git to /private/var/folders/jt/y5th6gms2xb412fyfxtnswbc0000gn/T/pip-req-build-4t00uvzj\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /private/var/folders/jt/y5th6gms2xb412fyfxtnswbc0000gn/T/pip-req-build-4t00uvzj\n",
      "  Resolved https://github.com/openai/whisper.git to commit ba3f3cd54b0e5b8ce1ab3de13e32122d0d5f98ab\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numba in /Users/danielfugisawa/Documents/playground/.conda/lib/python3.12/site-packages (from openai-whisper==20231117) (0.59.0)\n",
      "Requirement already satisfied: numpy in /Users/danielfugisawa/Documents/playground/.conda/lib/python3.12/site-packages (from openai-whisper==20231117) (1.26.2)\n",
      "Requirement already satisfied: torch in /Users/danielfugisawa/Documents/playground/.conda/lib/python3.12/site-packages (from openai-whisper==20231117) (2.2.0)\n",
      "Requirement already satisfied: tqdm in /Users/danielfugisawa/Documents/playground/.conda/lib/python3.12/site-packages (from openai-whisper==20231117) (4.66.1)\n",
      "Requirement already satisfied: more-itertools in /Users/danielfugisawa/Documents/playground/.conda/lib/python3.12/site-packages (from openai-whisper==20231117) (10.2.0)\n",
      "Requirement already satisfied: tiktoken in /Users/danielfugisawa/Documents/playground/.conda/lib/python3.12/site-packages (from openai-whisper==20231117) (0.6.0)\n",
      "Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in /Users/danielfugisawa/Documents/playground/.conda/lib/python3.12/site-packages (from numba->openai-whisper==20231117) (0.42.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/danielfugisawa/Documents/playground/.conda/lib/python3.12/site-packages (from tiktoken->openai-whisper==20231117) (2023.12.25)\n",
      "Requirement already satisfied: requests>=2.26.0 in /Users/danielfugisawa/Documents/playground/.conda/lib/python3.12/site-packages (from tiktoken->openai-whisper==20231117) (2.31.0)\n",
      "Requirement already satisfied: filelock in /Users/danielfugisawa/Documents/playground/.conda/lib/python3.12/site-packages (from torch->openai-whisper==20231117) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/danielfugisawa/Documents/playground/.conda/lib/python3.12/site-packages (from torch->openai-whisper==20231117) (4.9.0)\n",
      "Requirement already satisfied: sympy in /Users/danielfugisawa/Documents/playground/.conda/lib/python3.12/site-packages (from torch->openai-whisper==20231117) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/danielfugisawa/Documents/playground/.conda/lib/python3.12/site-packages (from torch->openai-whisper==20231117) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Users/danielfugisawa/Documents/playground/.conda/lib/python3.12/site-packages (from torch->openai-whisper==20231117) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /Users/danielfugisawa/Documents/playground/.conda/lib/python3.12/site-packages (from torch->openai-whisper==20231117) (2024.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/danielfugisawa/Documents/playground/.conda/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/danielfugisawa/Documents/playground/.conda/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/danielfugisawa/Documents/playground/.conda/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/danielfugisawa/Documents/playground/.conda/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/danielfugisawa/Documents/playground/.conda/lib/python3.12/site-packages (from jinja2->torch->openai-whisper==20231117) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/danielfugisawa/Documents/playground/.conda/lib/python3.12/site-packages (from sympy->torch->openai-whisper==20231117) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install openai yt-dlp\n",
    "!pip install git+https://github.com/openai/whisper.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydub in /Users/danielfugisawa/Documents/playground/.conda/lib/python3.12/site-packages (0.25.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "import urllib\n",
    "from IPython.display import Audio\n",
    "from pathlib import Path\n",
    "from pydub import AudioSegment\n",
    "import ssl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "def download_youtube_audio(youtube_url, output_path=\"audio.mp3\"):\n",
    "    command = f\"yt-dlp -x --audio-format mp3 -o {output_path} {youtube_url}\"\n",
    "    subprocess.run(command.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use pydub AudioSegment to split the audio into 3 equal parts\n",
    "def split_audio(input_path, output_path, num_parts=3):\n",
    "    audio = AudioSegment.from_file(input_path)\n",
    "    duration = len(audio)\n",
    "    part_duration = duration // num_parts\n",
    "    for i in range(num_parts):\n",
    "        start = i * part_duration\n",
    "        end = (i + 1) * part_duration\n",
    "        part = audio[start:end]\n",
    "        part.export(f\"{output_path}/part_{i}.mp3\", format=\"mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "\n",
    "def transcribe_audio(audio_path, model=\"base\"):\n",
    "    model = whisper.load_model(model)\n",
    "    result = model.transcribe(audio_path, language=\"pt\")\n",
    "    return result[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def milliseconds_until_sound(sound, silence_threshold_in_decibels=-20.0, chunk_size=10):\n",
    "    trim_ms = 0  # ms\n",
    "\n",
    "    assert chunk_size > 0  # to avoid infinite loop\n",
    "    while sound[trim_ms:trim_ms+chunk_size].dBFS < silence_threshold_in_decibels and trim_ms < len(sound):\n",
    "        trim_ms += chunk_size\n",
    "\n",
    "    return trim_ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_start(filepath):\n",
    "    path = Path(filepath)\n",
    "    directory = path.parent\n",
    "    filename = path.name\n",
    "    audio = AudioSegment.from_file(filepath, format=\"wav\")\n",
    "    start_trim = milliseconds_until_sound(audio)\n",
    "    trimmed = audio[start_trim:]\n",
    "    new_filename = directory / f\"trimmed_{filename}\"\n",
    "    trimmed.export(new_filename, format=\"wav\")\n",
    "    return trimmed, new_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_corrected_transcript(temperature, system_prompt, audio_file):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        temperature=temperature,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system_prompt\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": transcribe(audio_file, \"\")\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    return response['choices'][0]['message']['content']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "openai.api_key = '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'\n",
    "\n",
    "def process_transcription(text):\n",
    "    # Using the OpenAI \"text-davinci-003\" model to summarize the text\n",
    "    response = openai.Completion.create(\n",
    "        model=\"text-davinci-003\",  # Updated to \"model\" parameter\n",
    "        prompt=\"Summarize this text: \" + text,\n",
    "        temperature=0.7,\n",
    "        max_tokens=150,\n",
    "        top_p=1.0,\n",
    "        frequency_penalty=0.0,\n",
    "        presence_penalty=0.0\n",
    "    )\n",
    "    return response.choices[0].text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=QY4h1ni7-Gg\n",
      "[youtube] QY4h1ni7-Gg: Downloading webpage\n",
      "[youtube] QY4h1ni7-Gg: Downloading ios player API JSON\n",
      "[youtube] QY4h1ni7-Gg: Downloading android player API JSON\n",
      "[youtube] QY4h1ni7-Gg: Downloading m3u8 information\n",
      "[info] QY4h1ni7-Gg: Downloading 1 format(s): 251\n",
      "[download] audio.mp3 has already been downloaded\n",
      "[ExtractAudio] Not converting audio audio.mp3; file is already in target format mp3\n"
     ]
    }
   ],
   "source": [
    "youtube_url = \"https://www.youtube.com/watch?v=QY4h1ni7-Gg\"\n",
    "output_path = \"audio_parts\"\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "\n",
    "#Combine all the functions to get the video, split the audio, preprocess the audio, transcribe the audio, correct the transcription, and summarize the corrected transcription\n",
    "# Step 1: Download the video\n",
    "download_youtube_audio(youtube_url, \"audio.mp3\")\n",
    "\n",
    "# Step 2: Split the audio\n",
    "split_audio(\"audio.mp3\", \"audio_parts\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 3: Preprocess the audio\n",
    "# Milliseconds until sound for all parts\n",
    "parts = [AudioSegment.from_file(f\"audio_parts/part_{i}.mp3\") for i in range(3)]\n",
    "start_times = [milliseconds_until_sound(part) for part in parts]\n",
    "# Trim the audio\n",
    "trimmed_parts = [part[start_time:] for part, start_time in zip(parts, start_times)]\n",
    "# Export the trimmed audio\n",
    "for i, part in enumerate(trimmed_parts):\n",
    "    part.export(f\"audio_parts/trimmed_part_{i}.mp3\", format=\"mp3\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielfugisawa/Documents/playground/.conda/lib/python3.12/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "/Users/danielfugisawa/Documents/playground/.conda/lib/python3.12/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "/Users/danielfugisawa/Documents/playground/.conda/lib/python3.12/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 4: Transcribe the audio\n",
    "transcriptions = [transcribe_audio(f\"audio_parts/trimmed_part_{i}.mp3\") for i in range(3)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#save the transcriptions to a file\n",
    "with open(\"transcriptions.txt\", \"w\") as file:\n",
    "    for i, transcription in enumerate(transcriptions):\n",
    "        file.write(f\"Part {i + 1}:\\n\")\n",
    "        file.write(transcription)\n",
    "        file.write(\"\\n\\n\")\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_corrected_transcript(temperature, system_prompt, audio_file):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        temperature=temperature,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system_prompt\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": transcribe_audio(audio_file)\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    return response['choices'][0]['message']['content']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "openai.api_key = 'your-correct-api-key'\n",
    "\n",
    "openai.api_key = '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'\n",
    "\n",
    "client = openai.OpenAI(api_key='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')\n",
    "# Create a chat completion\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Correct the transcription:\"},\n",
    "        {\"role\": \"user\", \"content\": transcription},\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Retrieve the message content from the response\n",
    "corrected_transcription = response.choices[0].message.content.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries = [process_transcription(transcription) for transcription in corrected_transcriptions]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the summaries to a file\n",
    "with open(\"summaries.txt\", \"w\") as file:\n",
    "    for i, summary in enumerate(summaries):\n",
    "        file.write(f\"Part {i + 1}:\\n\")\n",
    "        file.write(summary)\n",
    "        file.write(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "def extract_entities(text):\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    doc = nlp(text)\n",
    "    entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "    return entities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
